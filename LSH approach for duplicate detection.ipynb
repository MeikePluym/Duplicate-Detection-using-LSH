{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import math\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1624\n"
     ]
    }
   ],
   "source": [
    "#import json data\n",
    "with open('TVs-all-merged.json') as file:\n",
    "    original_data=json.load(file)\n",
    "\n",
    "new_data = {}\n",
    "i = 1\n",
    "for key in original_data.keys():\n",
    "    for description in original_data[key]:\n",
    "        new_data[i] = description\n",
    "        i+=1\n",
    "print(len(new_data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain bootstrapped data (about 60%)\n",
    "bootData={}\n",
    "numBootstraps=int(len(new_data.keys())*0.63) #63% of data for bootstrap\n",
    "for i in range(1, numBootstraps+1):\n",
    "    index=random.randint(1, len(new_data.keys()))\n",
    "    #bootData[i]=new_data[index].items()\n",
    "    bootData[i]=(new_data[index])\n",
    "\n",
    "data=bootData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning title and featuresMap input for hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal term for 'inch' and 'hz' and make everything lower case\n",
    "def preprocess(text):\n",
    "    CleaningDictionary = {'inch':['Inch', 'inches', '\"', '-inch', ' inch', 'inch']\n",
    "                    ,'hz':['Hertz', 'hertz', 'Hz', 'HZ', ' hz', '-hz', 'hz']}\n",
    "    for normVal in CleaningDictionary.keys():\n",
    "        possible=CleaningDictionary[normVal]\n",
    "        for notNormVal in possible:\n",
    "            text=text.replace(notNormVal, normVal)\n",
    "    title=text.lower()\n",
    "    title=re.sub(\"[^a-zA-Z0-9\\s\\.]\",\"\",title)\n",
    "    return title\n",
    "\n",
    "#preprocess all text in titles and featuresMap\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    data[i]['title']=preprocess(data[i]['title'])\n",
    "    for feature in data[i]['featuresMap']:\n",
    "        data[i]['featuresMap'][feature]=preprocess(data[i]['featuresMap'][feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern='([a-zA-Z0-9]*(([0-9]+)|([0-9]+))[a-zA-Z0-9]*)'\n",
    "shingles_title=[]\n",
    "num_sig=512\n",
    "\n",
    "#extract all model words from the title of the product\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    for titleWords in re.findall(pattern, data[i]['title']):\n",
    "        shingles_title.append(titleWords[0].strip()) #collection of all words\n",
    "        \n",
    "shingles=list(set(shingles_title))\n",
    "\n",
    "#extract model words which contain letters-numbers-letters or numbers-letters-numbers and add them twice\n",
    "modWordsPat='[a-zA-Z0-9][0-9]+[a-zA-Z]+[0-9]+[a-zA-Z0-9]|[a-zA-Z0-9]*[a-zA-Z]+[0-9]+[a-zA-Z]+[a-zA-Z0-9]+'\n",
    "shingles_copy=shingles\n",
    "for words in range(0, len(shingles)-1):\n",
    "    if re.match(modWordsPat, shingles[words]):\n",
    "        shingles_copy.append(shingles[words])\n",
    "shingles=shingles_copy #modelIDs are added twice\n",
    "\n",
    "#create a binary vector of model words for each product\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    all_prods=[]\n",
    "    bin_vecs=[]\n",
    "    \n",
    "    for titleWords in re.findall(pattern, data[i]['title']):\n",
    "        all_prods.append(titleWords[0].strip())\n",
    "    for word in shingles:\n",
    "        if word in all_prods:\n",
    "            bin_vecs.append(1)\n",
    "        else:\n",
    "            bin_vecs.append(0)\n",
    "            \n",
    "    data[i]['vector']=bin_vecs\n",
    "    #data[i]['signature']=[int(len(bin_vecs)/2)] * (int(len(bin_vecs) /2)) \n",
    "    data[i]['signature']=[num_sig] * (num_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHash algorithm, creating signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n",
      "50 done\n"
     ]
    }
   ],
   "source": [
    "#check is a number is a prime number\n",
    "def isPrime(n):\n",
    "    for i in range(2,int(n**0.5)+1):\n",
    "        if n%i==0:\n",
    "            return False\n",
    "    if n < int(len(bin_vecs) /2):\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "\n",
    "#construct the hash function for hashing the binary vectors to signatures\n",
    "def HashFunction(a,b,p,r):\n",
    "    return (a + b*r) % p \n",
    "\n",
    "primes = [i for i in range(0,len(shingles)) if isPrime(i)]\n",
    "\n",
    "HashFrame = pd.DataFrame({'HashFunction':list(range(0,num_sig))\n",
    "              ,'a': np.random.randint(0,len(shingles),size=num_sig)\n",
    "              ,'b': np.random.randint(0,len(shingles),size=num_sig)\n",
    "              ,'p': random.choices(primes,k=num_sig)})\n",
    "\n",
    "\n",
    "integercounter = 0\n",
    "\n",
    "#for the num_sig permutations of the binary vectors, add the number for first 1 in the vector as signature value\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    for index,row in HashFrame.iterrows():\n",
    "        x = 0\n",
    "        for entry in data[i]['vector']:\n",
    "            if entry == 1:\n",
    "                data[i]['signature'][index] = min(data[i]['signature'][index],\n",
    "                    HashFunction(int(row['a'])\n",
    "                    ,int(row['b'])\n",
    "                    ,int(row['p'])\n",
    "                    ,x))\n",
    "            x=x+1\n",
    "    integercounter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures=pd.DataFrame(None)\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    signatures=pd.concat([signatures, pd.DataFrame({i:data[i]['signature']})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>134</td>\n",
       "      <td>35</td>\n",
       "      <td>166</td>\n",
       "      <td>97</td>\n",
       "      <td>98</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>102</td>\n",
       "      <td>98</td>\n",
       "      <td>425</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>115</td>\n",
       "      <td>220</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>20</td>\n",
       "      <td>115</td>\n",
       "      <td>...</td>\n",
       "      <td>241</td>\n",
       "      <td>216</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>115</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>118</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>163</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>268</td>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>253</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>88</td>\n",
       "      <td>34</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>146</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>132</td>\n",
       "      <td>35</td>\n",
       "      <td>132</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>456</td>\n",
       "      <td>7</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>264</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>122</td>\n",
       "      <td>67</td>\n",
       "      <td>156</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>113</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>74</td>\n",
       "      <td>250</td>\n",
       "      <td>13</td>\n",
       "      <td>76</td>\n",
       "      <td>71</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>110</td>\n",
       "      <td>74</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>223</td>\n",
       "      <td>74</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>50</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>131</td>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>132</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>512</td>\n",
       "      <td>29</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>133</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>77</td>\n",
       "      <td>82</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>133</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>45</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>139</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "      <td>254</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>232</td>\n",
       "      <td>28</td>\n",
       "      <td>198</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>180</td>\n",
       "      <td>67</td>\n",
       "      <td>167</td>\n",
       "      <td>28</td>\n",
       "      <td>238</td>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512 rows Ã— 1023 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1     2     3     4     5     6     7     8     9     10    ...  1014  \\\n",
       "0     171    36    22   134    35   166    97    98    22    25  ...    36   \n",
       "1      76    21     7   115   220   115     3    80    20   115  ...   241   \n",
       "2       8    35     8     8   163     8     8     8     8     8  ...    17   \n",
       "3     120    78    43    35    88    34     7    54    50   146  ...    36   \n",
       "4     305    32    21     3    97   264    21    21     9    49  ...    42   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "507     1     1     8    74   250    13    76    71    55     6  ...    69   \n",
       "508    50    81     6     6   131    60     6     6   132     7  ...    29   \n",
       "509    57    18   133   126     0     1    14    77    82    12  ...    15   \n",
       "510   139     7   126   254    82    35    34    28    14    14  ...     7   \n",
       "511   180    67   167    28   238    43     5    97    31    31  ...    67   \n",
       "\n",
       "     1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
       "0      30    11    36    32   102    98   425    47    36  \n",
       "1     216    12    34   115    33    40   118    28    44  \n",
       "2     268     8    93     8     8     8   253     8    59  \n",
       "3     132    35   132    54    25    22   456     7   258  \n",
       "4     122    67   156    21    10    21   113    42    61  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "507   110    74    12    37   223    74   114     1    18  \n",
       "508    47     3    59     6    57     6   512    29   371  \n",
       "509    12    34    18   133    23    76    45    15    18  \n",
       "510   105    13     7    28   232    28   198    27     7  \n",
       "511    24    28    10   167    43    17    59    27    34  \n",
       "\n",
       "[512 rows x 1023 columns]"
      ]
     },
     "execution_count": 1228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH procedure using the generated signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set values for b and r (consequently setting the value for threshold t)\n",
    "n=len(signatures)\n",
    "b=64\n",
    "r=n/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hash all products with the same signatures in a band to the same buckets\n",
    "candidates=[]\n",
    "desc=list(signatures.columns)\n",
    "for band in range(0,b):\n",
    "    buckets=collections.defaultdict(list)\n",
    "    bandMatrix=signatures[(signatures.index>=band*r)&(signatures.index<band*r +r)]\n",
    "    for entry in desc:\n",
    "        buckets[tuple(bandMatrix[entry])].append(entry)\n",
    "    candidate=[x for x in list(buckets.values()) if len(x)>1]\n",
    "    for pair in candidate:\n",
    "        if pair not in candidates:\n",
    "            candidates.append(pair)\n",
    "candidates.sort()\n",
    "\n",
    "cands=candidates[:]\n",
    "\n",
    "#products hashed to the same bucket at least once form candidate pairs\n",
    "for m in candidates:\n",
    "    for n in cands:\n",
    "        if set(m).issubset(set(n)) and m!=n:\n",
    "            cands.remove(m)\n",
    "            break\n",
    "candidates=cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the candidates, make all combinations of 2 products to construct the candidate pairs\n",
    "comblist=[]\n",
    "for x in candidates:\n",
    "    if (len(x)==2)&(x not in comblist):\n",
    "        comblist.append(x)\n",
    "    else:\n",
    "        for subset in itertools.combinations(x,2):\n",
    "            if (list(subset) not in comblist):\n",
    "                comblist.append(list(subset))\n",
    "\n",
    "comblist.sort()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 1233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comblist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates=comblist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the similarity and presenting estimated duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing of the title and featureMap for comparison\n",
    "def keyToString(key):\n",
    "    key=re.sub(r'[^\\w\\s]','',key)\n",
    "    string=key.lower()\n",
    "    string=string.replace(\" \", \"\")\n",
    "    return string\n",
    "\n",
    "#preprocessing of the featureMap for comparison\n",
    "def createKeyQ(keys): #list of all keys as strings\n",
    "    lstOfKeys=[]\n",
    "    for key in keys:\n",
    "        lstOfKeys.append(keyToString(key))\n",
    "    return lstOfKeys\n",
    "\n",
    "#calculate the similarity between two titles\n",
    "similarities=[]\n",
    "for pair in range(0, len(candidates)-1):\n",
    "    init1=preprocess(data[candidates[pair][0]]['title'])\n",
    "    init2=preprocess(data[candidates[pair][1]]['title'])\n",
    "    title1=keyToString(init1)\n",
    "    title2=keyToString(init2)\n",
    "    sim=SequenceMatcher(None, title1, title2).ratio()\n",
    "    similarities.append(sim)\n",
    "\n",
    "#calculate the similarity between two featureMaps\n",
    "for pair in range(0, len(candidates)-1): #for each pair in candidates\n",
    "    #obtain list of strings for keys and values of pairs\n",
    "    prod1=createKeyQ(data[candidates[pair][0]]['featuresMap'].keys())\n",
    "    prod2=createKeyQ(data[candidates[pair][1]]['featuresMap'].keys())\n",
    "    val1=createKeyQ(data[candidates[pair][0]]['featuresMap'].values())\n",
    "    val2=createKeyQ(data[candidates[pair][1]]['featuresMap'].values())\n",
    "    \n",
    "    w=0\n",
    "    sim=0\n",
    "    avgSim=0\n",
    "    newSim=0\n",
    "    for i in range(0, len(prod1)):\n",
    "        for j in range(0, len(prod2)):\n",
    "            keySim=SequenceMatcher(None, prod1[i], prod2[j]).ratio()\n",
    "            if keySim>=0.8: #if the keys of the featureMap match significantly, add the similarity of the values\n",
    "                valueSim=SequenceMatcher(None, val1[i], val2[j]).ratio()\n",
    "                weight=keySim\n",
    "                sim=sim+(weight*valueSim)\n",
    "                w=w+weight\n",
    "    if w>0:\n",
    "        avgSim=sim/w\n",
    "    \n",
    "    if avgSim != 0:\n",
    "        newSim=(similarities[pair]+avgSim)/2\n",
    "        similarities[pair]=newSim #similarity measure is average of the similarity between titles and featureMap\n",
    "\n",
    "\n",
    "#propose all pairs with similarity>50% as duplicates\n",
    "sameProducts=[i for i,e in enumerate(similarities) if e>=0.5]\n",
    "    \n",
    "vectorOfPairs=[]\n",
    "for index, value in enumerate(sameProducts):\n",
    "    vectorOfPairs.append(candidates[value])\n",
    "    \n",
    "modelIDs=[]\n",
    "for i in range(1, len(data.keys())+1):\n",
    "    #modelIDs[i]=data[i]['modelID']\n",
    "    modelIDs.append(data[i]['modelID'])\n",
    "\n",
    "#identify all true duplicate pairs\n",
    "def listDuplicates(modelIDs):\n",
    "    dups=collections.defaultdict(set)\n",
    "    for index, product in enumerate(modelIDs):\n",
    "        dups[product].add(index)\n",
    "    duplicates=set()\n",
    "    for match in dups.values():\n",
    "        if len(match)>1:\n",
    "            for pair in itertools.combinations(match,2):\n",
    "                duplicates.add(pair)\n",
    "    return duplicates\n",
    "\n",
    "duplicates=listDuplicates(modelIDs)\n",
    "\n",
    "TP=0\n",
    "truePos=[]\n",
    "trueMod=[]\n",
    "#calculate the number of true positive duplicates\n",
    "for i in range(0, len(vectorOfPairs)-1):\n",
    "    if data[vectorOfPairs[i][0]]['modelID']==data[vectorOfPairs[i][1]]['modelID']:\n",
    "        TP=TP+1 #number of true positives\n",
    "        trueMod.append(data[vectorOfPairs[i][1]]['modelID'])\n",
    "        truePos.append(vectorOfPairs[i])\n",
    "\n",
    "FP=len(vectorOfPairs)-TP #number of false positives\n",
    "FN=len(duplicates)-TP\n",
    "\n",
    "#evaluation measures\n",
    "pairCompl=TP/len(duplicates)\n",
    "pairQual=TP/len(candidates)\n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "F1=2*(precision*recall)/(precision+recall)\n",
    "F1star=2*(pairQual*pairCompl)/(pairQual+pairCompl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair completenes is: 0.8560606060606061\n",
      "Pair quality is: 0.18880534670008353\n",
      "F1-measure is: 0.3287272727272727\n",
      "F1*-measure is: 0.30937713894592744\n",
      "True positives: 452\n",
      "False positives: 1770\n",
      "False negatives: 76\n",
      "precision: 0.20342034203420342\n",
      "recall: 0.8560606060606061\n"
     ]
    }
   ],
   "source": [
    "#FOR B=64, R=8, E>0.5\n",
    "print('Pair completenes is: ' + str(pairCompl))\n",
    "print('Pair quality is: ' + str(pairQual))\n",
    "print('F1-measure is: ' + str(F1))\n",
    "print('F1*-measure is: ' + str(F1star))\n",
    "print('True positives: ' + str(TP))\n",
    "print('False positives: ' + str(FP))\n",
    "print('False negatives: ' + str(FN))\n",
    "print('precision: ' + str(precision))\n",
    "print('recall: ' + str(recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
